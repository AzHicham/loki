instance_name = 'my_coverage'
requests_socket = 'tcp://*:30001'

[data_source]
type = 's3'
bucket_name = 'loki'
bucket_region = 'http://s3_hostname/'
bucket_access_key = 'loki_rw'
bucket_secret_key = 'my_secret_key'
data_path_key = 'my_coverage/ntfs.zip'
bucket_timeout = '00:01:00'


[default_request_params]
leg_arrival_penalty = '00:02:00'
leg_walking_penalty = '00:02:00'
max_nb_of_legs = 10
max_journey_duration = '24:00:00'
too_late_threshold = '02:00:00'
real_time_level = 'base'

[rabbitmq]
endpoint = 'amqp://login:password@rabbitmq_hostname:5672/navitia'
exchange = 'navitia'
realtime_topics = [
    'shortterm.my_coverage',
    'another_topic',
]
realtime_update_interval = '00:00:30'
connect_retry_interval = '00:00:10'
reload_kirin_request_time_to_live = '00:00:02'
reload_kirin_timeout = '00:00:10'
reload_queue_expires = '02:00:00'
realtime_queue_expires = '02:00:00'

# Configures the connection to a chaos database that will be used
# to retreive the history of chaos disruptions when the public transport data is (re)loaded
# Optional.
# If not present, the retreival of past chaos disruptions will be disabled
[chaos]
# connection string to the chaos database
# for example : "postgres://guest:guest@localhost:5432/chaos"
database = 'postgres://login:password@chaos_hostname:5432/chaos'

# During reload of chaos disruption
# we will ask the database to send
# blocks of rows of size `batch_size`
# Optional.
# Defaults to 1_000_000
batch_size = 1_000_000
